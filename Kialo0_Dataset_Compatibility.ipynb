{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9247c20",
   "metadata": {},
   "source": [
    "# Kialo  0 - Transform Pickled Files of Kialo Debates to a Single Table\n",
    "\n",
    "## A. P. Young\n",
    "\n",
    "### 2022 April 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "702775d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetworkX version 1.10\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "START = time.time()\n",
    "import datetime\n",
    "from datetime import timedelta\n",
    "import os\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import networkx as nx\n",
    "print(\"NetworkX version\", nx.__version__)\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723e37f4",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This notebook contains code to convert pickled files of [Kialo](https://www.kialo.com/) debates to a single `.csv` file with the same data. The reason for this notebook is because the files provided were pickled in NetworkX version 1.x, and the methods in NetworkX version 2.x do not work due to version incompatibility.\n",
    "\n",
    "**To run this notebook, we assume you have NetworkX 1.x** (see the version print out above). Now do the following:\n",
    "\n",
    "  1. Go to https://netsys.surrey.ac.uk/datasets/graphnli/ (last accessed 13 April 2022).\n",
    "  \n",
    "  2. Fill out the form and request the dataset.\n",
    "  \n",
    "  3. Once the dataset request is approved, download and unzip the dataset. The folder's name is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68620883",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = './serializedGraphs/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f637564f",
   "metadata": {},
   "source": [
    "  4. Then run the notebook steps below, assuming that the folder is in the same directory as this notebook.\n",
    "  \n",
    "  5. The result is a `.csv` file, `kialo_debates.csv`, which you can use for downstream analysis, e.g. in online debate networks or NLP of the texts of the debates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e4d644",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "If you find this notebook useful, please cite:\n",
    "\n",
    "  * Young, A.P., Joglekar, S., Boschi, G. and Sastry, N., 2021. *Ranking comment sorting policies in online debates*. Argument & Computation, 12(2), pp.265-285.\n",
    "\n",
    "Paper [here](https://content.iospress.com/articles/argument-and-computation/aac200909).\n",
    "\n",
    "Given you are working with the Kialo dataset, please also cite:\n",
    "\n",
    "  * Agarwal, V., Joglekar, S., Young, A.P. and Sastry, N., 2022. *GraphNLI: A Graph-based Natural Language Inference Model for Polarity Prediction in Online Debates*. arXiv preprint arXiv:2202.08175.\n",
    "\n",
    "Preprint [here](https://arxiv.org/abs/2202.08175), paper to appear at The ACM Web Conference 2022, end-April 2022."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59494253",
   "metadata": {},
   "source": [
    "# Unpickle the Files\n",
    "\n",
    "We unpickle the files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e59a137",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_filepaths_excluding_hidden_files(directory_string):\n",
    "    \"\"\"\n",
    "    Input string that points to directory,\n",
    "    e.g. relative to this notebook\n",
    "    Output list of strings\n",
    "    i.e. names of directory's items and the filepath\n",
    "    Ignores any hidden files (see condition in list comprehension)\n",
    "    \"\"\"\n",
    "    return sorted([directory_string + item for item in os.listdir(directory_string) if not item.startswith('._')])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae79a8b7",
   "metadata": {},
   "source": [
    "First get the filepaths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09b09b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepaths = create_filepaths_excluding_hidden_files(folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1201a155",
   "metadata": {},
   "source": [
    "Then unpickle the files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a82fe2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle_file(filepath):\n",
    "    \"\"\"\n",
    "    Input filepath string of .pkl file\n",
    "    Output unpickled file\n",
    "    \"\"\"\n",
    "    with open(filepath, 'rb') as f:\n",
    "        answer = pickle.load(f)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00c19733",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle_file_from_list_of_filepaths(list_of_filepaths):\n",
    "    \"\"\"\n",
    "    Input list of strings (filepaths)\n",
    "    Apply the preceding unpickle_file function to all items in the input list\n",
    "    \"\"\"\n",
    "    # progress bar\n",
    "    return [unpickle_file(item) for item in tqdm(list_of_filepaths)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3419cef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1560/1560 [00:14<00:00, 107.29it/s]\n"
     ]
    }
   ],
   "source": [
    "debates = unpickle_file_from_list_of_filepaths(filepaths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1326fc4",
   "metadata": {},
   "source": [
    "# Get Graph Node and Edge Information\n",
    "\n",
    "Each pickled file is a NetworkX digraph, pickled in NetworkX version 1.x. The following methods follow the syntax of version 1.x. This is why this notebook assumes you have NetworkX 1.x.\n",
    "\n",
    "We first extract all nodes and their attributes into a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13a73286",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_all_nodes_with_date_into_list(mylist):\n",
    "    \"\"\"\n",
    "    Input list of nx graphs\n",
    "    Output list of pairs\n",
    "    - string node name\n",
    "    - node attributes dictionary\n",
    "    \"\"\"\n",
    "    answer = []\n",
    "    # progress bar\n",
    "    for item in tqdm(mylist):\n",
    "        answer += item.nodes(data = True)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0f1e41a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1560/1560 [00:00<00:00, 1829.63it/s]\n"
     ]
    }
   ],
   "source": [
    "debate_nodes = extract_all_nodes_with_date_into_list(debates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24dc339",
   "metadata": {},
   "source": [
    "We do the same for the edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "376b45e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_all_edges_with_date_into_list(mylist):\n",
    "    \"\"\"\n",
    "    Input list of nx graphs\n",
    "    Output list of triples\n",
    "    - string node name source node of edges\n",
    "    - string node name target node of edges\n",
    "    - dictionary of edge attributes\n",
    "    \"\"\"\n",
    "    answer = []\n",
    "    for item in tqdm(mylist):\n",
    "        answer += item.edges(data = True)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b2fad06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1560/1560 [00:01<00:00, 1056.06it/s]\n"
     ]
    }
   ],
   "source": [
    "debate_edges = extract_all_edges_with_date_into_list(debates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0df11b",
   "metadata": {},
   "source": [
    "# Merge Node and Edge Information into a Single Dataframe\n",
    "\n",
    "We turn each such list into a dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "adc11555",
   "metadata": {},
   "outputs": [],
   "source": [
    "def structure_list_of_nodes_or_edges_with_data_into_dataframe(mylist):\n",
    "    \"\"\"\n",
    "    Input a list of doubles (string, dict) or a list of triples (string1, string2, dict)\n",
    "    Output a dataframe with all of the dict keys as their separate columns\n",
    "    \"\"\"\n",
    "    answer = []\n",
    "    # progress bar\n",
    "    for item in tqdm(mylist):\n",
    "        # structure is either (a, mydict) or (a, b, mydict)\n",
    "        if len(item) == 2:\n",
    "            node_name = item[0]\n",
    "            myrow = item[-1]\n",
    "            myrow['source'] = node_name\n",
    "        if len(item) == 3:\n",
    "            source_node_name = item[0]\n",
    "            target_node_name = item[1]\n",
    "            myrow = item[-1]\n",
    "            myrow['source'] = source_node_name\n",
    "            myrow['target'] = target_node_name\n",
    "        answer.append(myrow)\n",
    "    return pd.DataFrame(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f7d0d4dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 329013/329013 [00:00<00:00, 440685.33it/s]\n"
     ]
    }
   ],
   "source": [
    "debate_nodes_df = structure_list_of_nodes_or_edges_with_data_into_dataframe(debate_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea3e518e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 327453/327453 [00:00<00:00, 404032.52it/s]\n"
     ]
    }
   ],
   "source": [
    "debate_edges_df = structure_list_of_nodes_or_edges_with_data_into_dataframe(debate_edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6a82b8",
   "metadata": {},
   "source": [
    "We change the order of the columns (optional, for aesthetic reasons):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ebdf5433",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_column_order = ['source',\n",
    "                     'author',\n",
    "                     'text',\n",
    "                     'created',\n",
    "                     'edited',\n",
    "                     'votes',\n",
    "                     'relation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b8c9a496",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_column_order = ['source',\n",
    "                     'target',\n",
    "                     'weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cfc673e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "debate_nodes_df = debate_nodes_df[node_column_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fdb7c92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "debate_edges_df = debate_edges_df[edge_column_order]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10373526",
   "metadata": {},
   "source": [
    "We then merge the edge information with the node information, resulting in a dataframe where each row is a (source) node, with also which (target) node it points to and any edge attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a08ef33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "debates_df = pd.merge(debate_nodes_df, debate_edges_df, how = 'left', on = ['source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3b05d873",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(329013, 9)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "debates_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363be5c8",
   "metadata": {},
   "source": [
    "For this dataframe, the `source` (node) column serves as an identifier for each row - this is verified below where every column value appears exactly once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3c9e1127",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(Counter(debates_df['source']).values())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370e3842",
   "metadata": {},
   "source": [
    "The merge of the edge information into the node information will have some nodes not be sources to edges. We define those targets to be `-1` and their edge weights is zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8317d6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "debates_df['target'] = debates_df['target'].fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a32b67e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "debates_df['weight'] = debates_df['weight'].fillna(0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8363fc10",
   "metadata": {},
   "source": [
    "# Delete Redundant Feature - `relation`\n",
    "\n",
    "There is a column called `relation` which has the same information as the `weight` column, as shown by the following correlation matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "97a35807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>relation</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>relation</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          relation  weight\n",
       "relation       1.0     1.0\n",
       "weight         1.0     1.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "debates_df[['relation', 'weight']].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500233ed",
   "metadata": {},
   "source": [
    "... and also the following counters of pairs of values. Notice the value $1$ matches with $1$, $-1$ matches with $-1$ and $0$ matches with $0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ee679dc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({(1, 1.0): 139722, (-1, -1.0): 184651, (0, 0.0): 4640})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(zip(debates_df['relation'], debates_df['weight']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d0fdc6",
   "metadata": {},
   "source": [
    "This means we are justified in dropping the `relation` column, because its information is already contained inthe `weight` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "37437423",
   "metadata": {},
   "outputs": [],
   "source": [
    "debates_df = debates_df.drop(columns = 'relation')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e86607",
   "metadata": {},
   "source": [
    "We also change the values of the `weight` column into integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7ef76906",
   "metadata": {},
   "outputs": [],
   "source": [
    "debates_df['weight'] = debates_df['weight'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b2c4a3",
   "metadata": {},
   "source": [
    "# Splitting the `votes` Column\n",
    "\n",
    "The `votes` column consists of a length-5 list of integers. This corresponds to the five categories in Kialo voting, where the numbers in each list position count the number of votes, and\n",
    "\n",
    "  0. Index `0` refers to the category \"This claim is false.\"\n",
    "  \n",
    "  1. Index `1` refers to the category \"This claim is improbable.\"\n",
    "  \n",
    "  2. Index `2` refers to the category \"This claim is plausible.\"\n",
    "  \n",
    "  3. Index `3` refers to the category \"This claim is probable.\"\n",
    "  \n",
    "  4. Index `4` refers to the category \"This claim is true.\"\n",
    "  \n",
    "See [here](https://www.kialo.com/the-existence-of-god-2629) for an example: click on the horizontal blue bar above the claim, and then the little icon on the upper left (with three vertical bars of ascending height).\n",
    "\n",
    "We split the `votes` column into five columns and rename them as `vote_category0`, `vote_category1`... etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9f975366",
   "metadata": {},
   "outputs": [],
   "source": [
    "votes_subdf = pd.DataFrame(list(debates_df['votes']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9886aae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vote_column_names = []\n",
    "for index in range(5):\n",
    "    item = 'vote_category' + str(index)\n",
    "    vote_column_names.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eb64bc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "votes_subdf.columns = vote_column_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4cf5f6",
   "metadata": {},
   "source": [
    "We partition the original dataframe and insert the five `votes` columns in the middle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "94ab883c",
   "metadata": {},
   "outputs": [],
   "source": [
    "votes_index = list(debates_df).index('votes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "64b37585",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = debates_df[list(debates_df)[:votes_index]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "41d7bf79",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = debates_df[list(debates_df)[votes_index+1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "aff93ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "debates_df = pd.concat([df1, votes_subdf, df2], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d38b751a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(329013, 12)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "debates_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e733ba8a",
   "metadata": {},
   "source": [
    "# Output Dataframe\n",
    "\n",
    "We have thus cleaned the pickled files into a single table, which overcomes any NetworkX incompatibility issues, and allows for the debate structure to be reconstructed (by following `source` and `target` relations, where `weight` is an edge attribute and everything else is a node attribute).\n",
    "\n",
    "We output the dataframe into a single `csv` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6020a04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "debates_df.to_csv('kialo_debates.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d88932e",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "\n",
    "This notebook has cleaned a series of pickled Kialo debates (NetworkX directed graphs) into a single table for downstream analysis, from which the debate structure can be reconstructed, while also overcoming any version incompatibilities from NetworkX."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "84f1f741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Notebook done in 0:00:34.535702.'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Notebook done in \" + str(timedelta(seconds = time.time() - START)) + '.'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
